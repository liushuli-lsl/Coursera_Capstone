{"nbformat_minor": 1, "cells": [{"source": "# Sentiment Analysis and Rating Prediction From The Review Text", "cell_type": "markdown", "metadata": {}}, {"source": "Sentiment ananlysis and rating prediction are among the imporant machine learning topics that help companies find if the users are happy or unhappy with the service/product provided. The users write reviews of the products/services on various platforms, such as social networking websites like Facebook and Twitter, Blogs, and service offering websites. The ananlysis of such reviews to find the coustomer satisfaction will be helpful for companies to improve their products as well as the customer service.\n\nIn this project, I aim to build a machine learning system that will predict the user rating from his text review. Precisely, I will work on building the models for the following.\n\n1. Predict the users' sentiments (positive or negative).\n2. Predict his product/service rating on a scale of 1 to 5.\n\nI have already done the ETL in the other notebook. So here, I will just load the data prepare it for the model training, valiadation and testing and describe the deep learning model employed. In this notebook, I will just focus on the sentiment predcitction, i.e. binary-classfication. For rating prediction, i.e. the multiclass classification, I have described the modeling in another notebook.", "cell_type": "markdown", "metadata": {}}, {"source": "So, let's just start with loading the required libraries.", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport pandas as pd\nimport gzip\nimport glob\nimport os\nimport re", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, GRU, Convolution1D, Flatten, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "execution_count": 5}, {"source": "## Loading the data from CSV", "cell_type": "markdown", "metadata": {}}, {"source": "df_sentiments = pd.read_csv('AmazonBookReviews_Sentiment.csv')\ndf_sentiments.shape", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "(440262, 3)"}, "execution_count": 59, "metadata": {}}], "execution_count": 59}, {"source": "lenthsStr = df_sentiments['reviewText'].apply(str).map(len)\nmaxlength = max(lenthsStr)\nmaxindex = lenthsStr[lenthsStr == maxlength].index[0]\nprint('The length of longest review text: '+ str(maxlength))\nprint('The index of review with maximum length: '+ str(maxindex))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "The length of longest review text: 499\nThe index of review with maximum length: 93\n"}], "execution_count": 61}, {"source": "## Spliting Data Set into Train, Validation and Test", "cell_type": "markdown", "metadata": {}}, {"source": "X_train, X_test, y_train, y_test = train_test_split(df_sentiments['reviewText'], df_sentiments['sentiment'], test_size=0.2, random_state=1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 62}, {"source": "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 63}, {"source": "print(X_train.shape)\nprint(X_train[0:5])\nprint(y_train.shape)\nprint(y_train[0:5])\n\ndf_train = pd.concat([X_train, y_train], axis=1)\ndf_train.groupby('sentiment').count()/df_train.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(281767,)\n29672     I LOVED Brown River Queen.  However, because i...\n305974    If you like Dave Barry's sense of humor, then ...\n377265    OMG I love this series its got romance,action,...\n277198    GREAT STORY, so I bought it for my kindle.  Th...\n363491    Surprising ending.  I liked the book and chara...\nName: reviewText, dtype: object\n(281767,)\n29672     1.0\n305974    1.0\n377265    1.0\n277198    1.0\n363491    1.0\nName: sentiment, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "           reviewText\nsentiment            \n0.0          8.093922\n1.0         91.906078", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>8.093922</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>91.906078</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 64, "metadata": {}}], "execution_count": 64}, {"source": "print(X_test.shape)\nprint(X_test[0:5])\nprint(y_test.shape)\nprint(y_test[0:5])\ndf_test = pd.concat([X_test, y_test], axis=1)\ndf_test.groupby('sentiment').count()/df_test.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(88053,)\n186694    Intresting mix of vocations, and how people ca...\n17142     John Holt's writings are very engrossing and e...\n302953    Enjoyable and thought-provoking. This was my H...\n159171    Interesting idea, not well executed.  There wa...\n155024    I started reading the Slavers Wars series by M...\nName: reviewText, dtype: object\n(88053,)\n186694    1.0\n17142     1.0\n302953    1.0\n159171    0.0\n155024    1.0\nName: sentiment, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "           reviewText\nsentiment            \n0.0          8.182572\n1.0         91.817428", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>8.182572</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>91.817428</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 65, "metadata": {}}], "execution_count": 65}, {"source": "print(X_val.shape)\nprint(X_val[0:5])\nprint(y_val.shape)\nprint(y_val[0:5])\ndf_val = pd.concat([X_val, y_val], axis=1)\ndf_val.groupby('sentiment').count()/df_val.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(70442,)\n374739    This is a funny and illuminating book, focused...\n119343    Great read. Loved this story of three sisters ...\n9476      The insights and stories really help you to sl...\n250850    Wow! Odd has always been my favorite. This sho...\n41347     I've been a Kennedy fan for years, their flaws...\nName: reviewText, dtype: object\n(70442,)\n374739    1.0\n119343    1.0\n9476      1.0\n250850    1.0\n41347     1.0\nName: sentiment, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "           reviewText\nsentiment            \n0.0           8.28483\n1.0          91.71517", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>sentiment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>8.28483</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>91.71517</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 66, "metadata": {}}], "execution_count": 66}, {"source": "We see that the distribution of classess in train, validation and test set is representative of the resal data set.", "cell_type": "markdown", "metadata": {}}, {"source": "## Data Preparation  for Modeling", "cell_type": "markdown", "metadata": {}}, {"source": "In this step, we first tokenize the textual data into words and convert it into sequences of same length.", "cell_type": "markdown", "metadata": {}}, {"source": "### Tokenization", "cell_type": "markdown", "metadata": {}}, {"source": "%%time\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df_sentiments['reviewText'])\n", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 19.5 s, sys: 314 ms, total: 19.8 s\nWall time: 19.8 s\n"}], "execution_count": 67}, {"source": "vocab_size = len(tokenizer.word_index) + 1\nvocab_size", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "148508"}, "execution_count": 68, "metadata": {}}], "execution_count": 68}, {"source": "%%time\nsequence_train = tokenizer.texts_to_sequences(X_train)\nsequence_test = tokenizer.texts_to_sequences(X_test)\nsequence_val = tokenizer.texts_to_sequences(X_val)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 14.5 s, sys: 604 ms, total: 15.1 s\nWall time: 15.1 s\n"}], "execution_count": 69}, {"source": "%%time\nX_train_pad = pad_sequences(sequence_train, maxlen=maxlength)\nX_test_pad = pad_sequences(sequence_test, maxlen=maxlength)\nX_val_pad = pad_sequences(sequence_val, maxlen=maxlength)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 4.34 s, sys: 1.45 s, total: 5.78 s\nWall time: 5.77 s\n"}], "execution_count": 70}, {"source": "Let us convert the labels vector to a matrix (one-hot encoded) using to_categorical.", "cell_type": "markdown", "metadata": {}}, {"source": "y_train_label = to_categorical(np.asarray(y_train))\nprint(y_train[0:5])\ny_test_label = to_categorical(np.asarray(y_test))\nprint(y_test[0:5])\ny_val_label = to_categorical(np.asarray(y_val))\nprint(y_val[0:5])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "29672     1.0\n305974    1.0\n377265    1.0\n277198    1.0\n363491    1.0\nName: sentiment, dtype: float64\n186694    1.0\n17142     1.0\n302953    1.0\n159171    0.0\n155024    1.0\nName: sentiment, dtype: float64\n374739    1.0\n119343    1.0\n9476      1.0\n250850    1.0\n41347     1.0\nName: sentiment, dtype: float64\n"}], "execution_count": 71}, {"source": "y_train_label[0:5]", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "array([[ 0.,  1.],\n       [ 0.,  1.],\n       [ 0.,  1.],\n       [ 0.,  1.],\n       [ 0.,  1.]])"}, "execution_count": 72, "metadata": {}}], "execution_count": 72}, {"source": "## Model Training and Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "In this project, I decided to use three different deep learning models. The models and their evaluation follows.", "cell_type": "markdown", "metadata": {}}, {"source": "callback_list = [EarlyStopping(), ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5')]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 41}, {"source": "### GRU based Model", "cell_type": "markdown", "metadata": {}}, {"source": "# embedding_dimensions =  vocab_size**0.25\nembedding_dimensions = 100", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 42}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength))\nmodel.add(GRU(units=32, dropout=0.2))\nmodel.add(Dense(2, activation='sigmoid'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 43}, {"source": "Model compilation and training", "cell_type": "markdown", "metadata": {}}, {"source": "%%time\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 44}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label),\n         callbacks = callback_list)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 45}, {"source": "Model evaluations ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 46}, {"source": "### 1D CNN based Model", "cell_type": "markdown", "metadata": {}}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential() \nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength)) \nmodel.add(Convolution1D(64, 3, padding='same'))\nmodel.add(Convolution1D(32, 3, padding='same'))\nmodel.add(Convolution1D(16, 3, padding='same'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(180,activation='sigmoid'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, activation='sigmoid'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 47}, {"source": "Model compilation and training ...", "cell_type": "markdown", "metadata": {}}, {"source": "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 48}, {"source": "Model evaluation ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 49}, {"source": "### LSTM based Model", "cell_type": "markdown", "metadata": {}}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential() \nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength)) \nmodel.add(LSTM(100)) \nmodel.add(Dense(2, activation='sigmoid'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model compilation and training ...", "cell_type": "markdown", "metadata": {}}, {"source": "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model evaluation ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "## Conclusion", "cell_type": "markdown", "metadata": {}}, {"source": "We have trained three different deep learning models to predict the user ratings from the text of the review they wrote. ", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}